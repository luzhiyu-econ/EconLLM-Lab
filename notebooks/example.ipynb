{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基础调用示例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI调用示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# 填入你的实际 API Key\n",
    "client = OpenAI(api_key=\"<OpenAI API Key>\", base_url=\"https://api.openai.com/v1\")\n",
    "\n",
    "prompt = \"You are a helpful assistant\"\n",
    "input_text = \"What is the capital of France?\"\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "    {\"role\": \"system\",\"content\": prompt},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": input_text\n",
    "    }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=2048,  # 修改为 max_tokens\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    ")\n",
    "\n",
    "# 打印响应内容\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepSeek调用示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is **Paris**. Known for its rich history, iconic landmarks like the Eiffel Tower, and vibrant culture, Paris is one of the most famous cities in the world.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# 填入你的实际 API Key\n",
    "client = OpenAI(api_key=\"<DeepSeek API Key>\", base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "prompt = \"You are a helpful assistant\"\n",
    "input_text = \"What is the capital of France?\"\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "    {\"role\": \"system\",\"content\": prompt},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": input_text\n",
    "    }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=2048,  # 修改为 max_tokens\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    ")\n",
    "\n",
    "# 打印响应内容\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多线程调用示例\n",
    "## 默认调用4o mini，可根据需要修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "# -------------------------------\n",
    "# JSON解析模块（独立模块）\n",
    "# -------------------------------\n",
    "def default_json_parser(content, idx=None):\n",
    "    \"\"\"\n",
    "    默认的 JSON 解析器：\n",
    "    清理输入内容后尝试解析 JSON，\n",
    "    若成功则返回完整的字典，若失败返回空字典。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 去除代码块标记，清理内容\n",
    "        cleaned_content = content.replace('```json\\n', '').replace('```', '').strip()\n",
    "        parsed_result = json.loads(cleaned_content)\n",
    "        return parsed_result\n",
    "    except json.JSONDecodeError:\n",
    "        if idx is not None:\n",
    "            logging.warning(f\"警告: 第 {idx} 行解析 JSON 失败\")\n",
    "        return {}\n",
    "    except Exception as e:\n",
    "        if idx is not None:\n",
    "            logging.error(f\"错误: 第 {idx} 行解析失败 - {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "# -------------------------------\n",
    "# 限流处理器（控制请求频率）\n",
    "# -------------------------------\n",
    "class RateLimitedProcessor:\n",
    "    def __init__(self):\n",
    "        self.request_timestamps = []\n",
    "        self.MAX_RPM = 500\n",
    "        self.window_size = 60  # 60秒窗口\n",
    "\n",
    "    def _clean_old_records(self, current_time):\n",
    "        cutoff_time = current_time - timedelta(seconds=self.window_size)\n",
    "        self.request_timestamps = [ts for ts in self.request_timestamps if ts > cutoff_time]\n",
    "\n",
    "    def can_make_request(self):\n",
    "        \"\"\"检查是否可以发起新请求\"\"\"\n",
    "        current_time = datetime.now()\n",
    "        self._clean_old_records(current_time)\n",
    "        if len(self.request_timestamps) >= self.MAX_RPM:\n",
    "            return False\n",
    "        self.request_timestamps.append(current_time)\n",
    "        return True\n",
    "\n",
    "# -------------------------------\n",
    "# OpenAI文本处理器\n",
    "# -------------------------------\n",
    "class OpenAITextProcessor:\n",
    "    def __init__(self, api_key=None, model=None, base_url=None, json_parser=None):\n",
    "        self.client = OpenAI(api_key=api_key,base_url=base_url)\n",
    "        self.model = model\n",
    "        self.rate_limiter = RateLimitedProcessor()\n",
    "        self.n_workers = 14  # 优化后的线程数\n",
    "        # 如果未提供自定义解析器，则使用默认解析器\n",
    "        self.json_parser = json_parser if json_parser is not None else default_json_parser\n",
    "\n",
    "    def process_batch(self, df, text_column, prompt, batch_size=20, delay=1, json_parser=None):\n",
    "        \"\"\"\n",
    "        批量处理文本，支持灵活的 JSON 解析。\n",
    "        \n",
    "        参数:\n",
    "            df: 包含文本数据的 DataFrame\n",
    "            text_column: 文本所在的列名\n",
    "            prompt: 系统提示，用于 API 调用\n",
    "            batch_size: 每个批次处理的文本条数\n",
    "            delay: 每次请求后的延迟（秒）\n",
    "            json_parser: 可选的自定义 JSON 解析器，若不传入则使用实例内的解析器\n",
    "        \n",
    "        返回:\n",
    "            新的 DataFrame，包含原始数据及 API 返回结果（通过 JSON 解析获得的各字段）\n",
    "        \"\"\"\n",
    "        parser = json_parser if json_parser is not None else self.json_parser\n",
    "        results = []  # 保存每次请求解析后的结果（字典形式）\n",
    "\n",
    "        def process_chunk(chunk_data):\n",
    "            chunk_results = []\n",
    "            for idx, text in chunk_data:\n",
    "                # 限流检测：等待直到可以发送请求\n",
    "                while not self.rate_limiter.can_make_request():\n",
    "                    time.sleep(0.1)\n",
    "                try:\n",
    "                    response = self.client.chat.completions.create(\n",
    "                        model=self.model,\n",
    "                        messages=[\n",
    "                            {\"role\": \"system\", \"content\": prompt},\n",
    "                            {\"role\": \"user\", \"content\": text}\n",
    "                        ],\n",
    "                        temperature=0,\n",
    "                        max_tokens=40\n",
    "                    )\n",
    "                    # 使用解析器处理响应内容，得到字典格式结果\n",
    "                    parsed_result = parser(response.choices[0].message.content, idx)\n",
    "                    chunk_results.append(parsed_result)\n",
    "                    time.sleep(delay)\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"错误: 处理第 {idx} 行时发生异常: {str(e)}\")\n",
    "                    chunk_results.append({})\n",
    "            return chunk_results\n",
    "\n",
    "        # 将数据分成批次，保留行号信息\n",
    "        chunks = [\n",
    "            list(enumerate(df[text_column][i:i+batch_size]))\n",
    "            for i in range(0, len(df), batch_size)\n",
    "        ]\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=self.n_workers) as executor:\n",
    "            futures = list(tqdm(\n",
    "                executor.map(process_chunk, chunks),\n",
    "                total=len(chunks),\n",
    "                desc=\"Processing batches\"\n",
    "            ))\n",
    "            for chunk_results in futures:\n",
    "                results.extend(chunk_results)\n",
    "\n",
    "        # 将解析结果列表转为 DataFrame，并与原 DataFrame 合并\n",
    "        df_result = df.copy().reset_index(drop=True)\n",
    "        results_df = pd.json_normalize(results)\n",
    "        df_result = pd.concat([df_result, results_df], axis=1)\n",
    "\n",
    "        # 统计处理情况\n",
    "        success_count = sum(1 for r in results if r)\n",
    "        total_count = len(results)\n",
    "        success_rate = (success_count / total_count) * 100 if total_count > 0 else 0\n",
    "        logging.info(f\"处理完成: 总数 {total_count}, 成功 {success_count}, 成功率 {success_rate:.2f}%\")\n",
    "        \n",
    "        return df_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt= \"作为中文命名实体识别助手，你的任务是从政府采购公告中识别出对应的城市名称和采购金额，并进行标准化处理。\\n\\n- **城市名称识别**：标识并提取采购公告中出现的城市全称，如果为县级行政单位则转化为其所在的市级单位。\\n- **采购金额识别与转换**：提取公告中提到的采购金额。如果金额单位为“万元”，需要将其转换为元，即将其乘以一万。\\n\\n# 步骤\\n\\n1. 阅读并解析公告内容。\\n2. 查找并提取公告中的城市全称，同时识别城市行政单位。\\n3. 如果是县级单位，则记录为其所在的地级市。\\n4. 查找并提取采购金额，同时识别单位。\\n5. 如果金额单位是“万元”，则将金额乘以一万转换为“元”。\\n6. 提供一个包含城市全称和标准化后的采购金额的数据结构。\\n\\n# 输出格式\\n\\n以JSON格式提供输出，包含两个字段：\\n- \\\"city\\\": \\\"完整的城市名称\\\",\\n- \\\"amount\\\": 数字类型的采购金额（单位为元）\\n\\n# 示例\\n\\n- 输入：[政府采购公告文本]\\n\\n- 输出：\\n  ```json\\n  {\\n    \\\"city\\\": \\\"北京市\\\",\\n    \\\"amount\\\": 1000000\\n  }\\n  ```\\n\\n# 注意事项\\n\\n- 如果公告中未明确指出城市或金额，输出相应字段时请设为空或为0。\\n- 确保金额在转换时符合单位元的精度要求。\\n- 确保所有城市名都为地级市。\\n-中国地市级单位包括'市''州'以及部分'县'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 20/20 [00:24<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "processor = OpenAITextProcessor(api_key=\"<OpenAI API Key>\", base_url=\"https://api.openai.com/v1\",model=\"gpt-4o-mini\")\n",
    "df_result = processor.process_batch(\n",
    "    df=pd.read_csv(\"data/政府采购公告.csv\"),\n",
    "    text_column=\"公告内容\",\n",
    "    prompt=prompt,\n",
    "    batch_size=5,\n",
    ")\n",
    "df_result.to_csv(\"data/政府采购公告_结果.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
